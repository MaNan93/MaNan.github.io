<!DOCTYPE html>
<html lang="en">

<head>

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <meta charset="utf-8">

  
  <title>IEEE Standard 754 Floating Point Numbers</title>
  
  <link rel="sitemap" href="http://manan.ccsitemap.xml" />
  
  <link rel="canonical" href="http://manan.cc/IEEE-Standard-754-Floating-Point-Numbers/2021/07/29/">
  
  <meta name="description" content="IEEE Standard 754 floating point is the most common representation today for real numbers on computers, including Intel-based PCâ€™s, Macintoshes, and m">
  
  
  <meta name="author" content="MaNan">
  
  <meta property="og:image" content="http://manan.ccundefined">
  
  <meta property="og:site_name" content="Hexo" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="IEEE Standard 754 Floating Point Numbers" />
  
  <meta property="og:description" content="IEEE Standard 754 floating point is the most common representation today for real numbers on computers, including Intel-based PCâ€™s, Macintoshes, and m">
  
  <meta property="og:url" content="http://manan.cc/IEEE-Standard-754-Floating-Point-Numbers/2021/07/29/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="IEEE Standard 754 Floating Point Numbers">
  
  <meta name="twitter:description" content="IEEE Standard 754 floating point is the most common representation today for real numbers on computers, including Intel-based PCâ€™s, Macintoshes, and m">
  
  
  <meta name="twitter:image" content="http://manan.ccundefined">
  
  <meta name="twitter:url" content="http://manan.cc/IEEE-Standard-754-Floating-Point-Numbers/2021/07/29/" />

  <!-- Mobile Specific Metas
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <link rel="preload" href="../fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="../fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  
  
<link rel="stylesheet" href="/css/user.css">

  

  <!-- Favicon
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <link rel="icon" type="image/png" href="/images/favicon.png">

  <!-- Custom Theme Color Style
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  

<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn">ğŸŒ™</div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden>â˜€ï¸</div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      Hola!
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        
          
          <a target="_blank" rel="noopener" href="https://www.xidian.edu.cn/" class="ml">Works</a>
          
        
          
          <a href="/about/me" class="ml">AboutMe</a>
          
        
        
          
            <a href="mailto:manan93@live.com" target="_blank" class="ml">Email</a>
          
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>IEEE Standard 754 Floating Point Numbers</h2>

  <p>IEEE Standard 754 floating point is the most common representation today for real numbers on computers, including Intel-based PCâ€™s, Macintoshes, and most Unix platforms. This article gives a brief overview of IEEE floating point and its representation. Discussion of arithmetic implementation may be found in the book mentioned at the bottom of this article.</p>
<blockquote>
<p>ã€ŠIEEE Standard 754 floating pointã€‹æ˜¯ç°å¦‚ä»Šåœ¨è®¡ç®—æœºè¡¨ç¤ºå®é™…æ•°æœ€æ™®éçš„æ–¹æ³•ï¼ŒåŒ…æ‹¬intelå¹³å°çš„ä¸ªäººç”µè„‘ï¼Œéº¦é‡‘å¡”ç”µè„‘å’Œæœ€å¹¿æ³›çš„Unixå¹³å°.æœ¬æ–‡å¯¹å…¶ä½œäº†ç®€è¦çš„æ¦‚è¿°å’Œä¸¾ä¾‹è¡¨ç¤ºã€‚å…³äºç®—æœ¯è¡¨ç¤ºçš„è®¨è®ºè¯·å‚é˜…æœ¬æ–‡æœ«å°¾æåˆ°çš„ä¹¦ç±ã€‚</p>
</blockquote>
<blockquote>
<p><em>Authorï¼ˆåŸä½œè€…ï¼‰: Steve Hollasch</em><br>You may visit the siteï¼ˆä½ å¯ä»¥è®¿é—®åŸå§‹é“¾æ¥ï¼‰: <a target="_blank" rel="noopener" href="https://steve.hollasch.net/cgindex/coding/ieeefloat.html">https://steve.hollasch.net/cgindex/coding/ieeefloat.html</a></p>
</blockquote>
<h2 id="What-Are-Floating-Point-Numbers"><a href="#What-Are-Floating-Point-Numbers" class="headerlink" title="What Are Floating Point Numbers?"></a>What Are Floating Point Numbers?</h2><p>There are several ways to represent real numbers on computers. Fixed point places a radix point somewhere in the middle of the digits, and is equivalent to using integers that represent portions of some unit. For example, one might represent 1/100ths of a unit; if you have four decimal digits, you could represent 10.82, or 00.01. Another approach is to use rationals, and represent every number as the ratio of two integers.</p>
<blockquote>
<p>ä»€ä¹ˆæ˜¯æµ®ç‚¹æ•°ï¼Ÿ</p>
<p>åœ¨è®¡ç®—æœºä¸­æœ‰å¤šç§æ–¹å¼æ¥è¡¨ç¤ºå®é™…æ•°å€¼ã€‚å®šç‚¹ï¼Œæ˜¯å°†å°æ•°ç‚¹æ”¾ç½®åœ¨æ•°å­—çš„ä¸­é—´ï¼Œä¹Ÿå°±æ˜¯ä½¿ç”¨æ•´æ•°æ¥è¡¨ç¤ºæŸä¸ªå•ä½çš„ä¸€éƒ¨åˆ†ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œ1å¯ä»¥ä»£è¡¨æŸä¸ªå•ä½çš„1/100ï¼›å‡å¦‚æœ‰4ä¸ªåè¿›åˆ¶çš„æ•°å­—ï¼Œé‚£å®ƒä»¬å¯èƒ½æ„æˆ10.82æˆ–è€…00.01ã€‚è¿˜æœ‰ç§æ–¹å¼æ˜¯é‡‡ç”¨æœ‰ç†æ•°ï¼Œç”¨ä¸¤ä¸ªæ•´æ•°çš„æ¯”å€¼æ¥è¡¨ç¤ºæ•°å­—ã€‚</p>
</blockquote>
<p>Floating-point representation â€“ the most common solution â€“ uses scientific notation to encode numbers, with a base number and an exponent. For example, 123.456 could be represented as 1.23456 Ã— 10<sup>2</sup>. In hexadecimal, the number 123.abc might be represented as 1.23abc Ã— 16<sup>2</sup>. In binary, the number 10100.110 could be represented as 1.0100110 Ã— 2<sup>4</sup>.</p>
<blockquote>
<p>æµ®ç‚¹è¡¨ç¤ºæ³•â€”â€”æœ€å¸¸è§çš„è¡¨ç¤ºæ³•â€”â€”é‡‡ç”¨ç§‘å­¦è®¡æ•°æ³•æ¥è¡¨ç¤ºæ•°å­—ï¼Œç”±åŸºæ•°å’ŒæŒ‡æ•°æ¥è¡¨ç¤ºã€‚æ¯”å¦‚ï¼Œ123.456å¯ä»¥å†™æˆ1.23456 Ã— 10<sup>2</sup>ã€‚åå…­è¿›åˆ¶ä¸­ï¼Œ123.abcå¯ä»¥å†™æˆ1.23abc Ã— 16<sup>2</sup> ã€‚åŒæ ·åœ¨äºŒè¿›åˆ¶ä¸­ï¼Œ10100.110å¯è¡¨ç¤ºä¸º1.0100110 Ã— 2<sup>4</sup>ã€‚</p>
</blockquote>
<p>Floating-point solves a number of representation problems. Fixed-point has a fixed window of representation, which limits it from representing both very large and very small numbers. Also, fixed-point is prone to a loss of precision when two large numbers are divided.</p>
<blockquote>
<p>æµ®ç‚¹è¡¨ç¤ºæ³•èƒ½è§£å†³å¦‚ä½•è¡¨ç¤ºæ•°å­—çš„é—®é¢˜ã€‚è€Œå®šç‚¹æ•°è¡¨ç¤ºæ³•çš„è¡¨ç¤ºçª—å£ï¼ˆæ³¨ï¼šä¹Ÿå°±æ˜¯å½“å®šç‚¹ä½å®½ç¡®å®šæ—¶ï¼Œå®ƒçš„æœ€å¤§å€¼å’Œæœ€å°å€¼å°±ç¡®å®šäº†ï¼‰æ˜¯å—é™çš„ï¼Œå¯¼è‡´å®šç‚¹æ—¢ä¸èƒ½è¡¨ç¤ºéå¸¸å¤§çš„æ•°ï¼Œä¹Ÿä¸èƒ½è¡¨ç¤ºç‰¹åˆ«å°çš„æ•°ã€‚å¹¶ä¸”å®šç‚¹è¡¨ç¤ºæ³•åœ¨ä¸¤ä¸ªè¾ƒå¤§æ•°å­—ç›¸é™¤çš„æ—¶å€™ä¼šæœ‰ç²¾åº¦æŸå¤±ã€‚</p>
</blockquote>
<p>Floating-point, on the other hand, employs a sort of â€œsliding windowâ€ of precision appropriate to the scale of the number. This allows it to represent numbers from 1,000,000,000,000 to 0.0000000000000001 with ease, and while maximizing precision (the number of digits) at both ends of the scale.</p>
<blockquote>
<p>å¦ä¸€æ–¹é¢ï¼Œæµ®ç‚¹æ•°å…·æœ‰â€œæµ®åŠ¨çª—å£â€ï¼Œå¯ä»¥æ ¹æ®æ•°å­—çš„å¤§å°ç²¾ç¡®åœ°å˜åŒ–ã€‚è¿™ä½¿å¾—æµ®ç‚¹æ•°å¾ˆå®¹æ˜“åœ°è¡¨ç¤ºå‡º0.0000000000000001åˆ°1,000,000,000,000ä¹‹é—´çš„æ•°å­—ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°ä¿è¯ä¸¤ç«¯çš„ç²¾åº¦ï¼ˆå–å†³äºæ•°å­—çš„ä½æ•°ï¼‰ã€‚</p>
</blockquote>
<h2 id="Storage-Layout"><a href="#Storage-Layout" class="headerlink" title="Storage Layout"></a>Storage Layout</h2><p>IEEE floating point numbers have three basic components: the sign, the exponent, and the mantissa. The mantissa is composed of the fraction and an implicit leading digit (explained below). The exponent base (2) is implicit and need not be stored.</p>
<blockquote>
<p>å­˜å‚¨æ–¹å¼</p>
<p>IEEEæµ®ç‚¹æ•°ç”±ä¸‰ä¸ªåŸºæœ¬å•å…ƒç»„æˆï¼šç¬¦å·ä½ï¼ŒæŒ‡æ•°å’Œå°¾æ•°ã€‚å°¾æ•°ç”±å°æ•°å’Œä¸€ä¸ªéšå«çš„å‰å¯¼ä½æ„æˆã€‚å‰å¯¼ä½æ˜¯éšå«çš„ï¼Œä¸éœ€è¦å­˜å‚¨ã€‚</p>
<p>æ³¨ï¼šthe leading digit, the first digit of a number, å°±æ˜¯æ•°å­—ä»å·¦å‘å³æ•°çš„ç¬¬ä¸€ä½ã€‚åœ¨è®¡ç®—æœºä¸­ï¼Œå­˜å‚¨æ•°æ˜¯ä»¥äºŒè¿›åˆ¶æ ¼å¼å­˜å‚¨ã€‚é‚£ä¹ˆå®ƒçš„å‰å¯¼æ•°åªèƒ½æ˜¯0æˆ–è€…1ï¼Œæ¯”å¦‚0.xxxxxxæˆ–è€…1.xxxxxxï¼Œé‚£å¯¹åº”çš„å‰å¯¼æ•°å°±æ²¡å¿…è¦ä¿å­˜ï¼Œåªéœ€è¦è§„å®šå¥½å‰å¯¼æ•°æ˜¯0æˆ–è€…1å°±è¡Œäº†ã€‚</p>
</blockquote>
<p>The following table shows the layout for single (32-bit) and double (64-bit) precision floating-point values. The number of bits for each field are shown, followed by the bit ranges in square brackets. 00 = least-significant bit.</p>
<blockquote>
<p>ä¸‹è¡¨æ˜¯å•ç²¾åº¦ï¼ˆ32ä½ï¼‰å’ŒåŒç²¾åº¦ï¼ˆ64ä½ï¼‰æµ®ç‚¹å€¼çš„å­˜å‚¨æ ¼å¼ã€‚æ¯ä¸ªåŸŸçš„ä½æ•°èŒƒå›´å¦‚æ–¹æ‹¬å·å†…çš„æ•°å­—æ‰€ç¤ºã€‚00è¡¨ç¤ºæœ€ä½ä½ã€‚</p>
</blockquote>
<p>â€‹                                            <em>Floating Point Components</em></p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">Sign</th>
<th align="center">Exponent</th>
<th align="center">Fraction</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Single Precision</td>
<td align="center">1 [31]</td>
<td align="center">8 [30â€“23]</td>
<td align="center">23 [22â€“00]</td>
</tr>
<tr>
<td align="center">Double Precision</td>
<td align="center">1 [63]</td>
<td align="center">11 [62â€“52]</td>
<td align="center">52 [51â€“00]</td>
</tr>
</tbody></table>
<p>Laid out as bits, floating point numbers look like this:</p>
<blockquote>
<p>æŒ‰ä½å±•ç¤ºï¼Œæµ®ç‚¹æ•°é•¿è¿™æ ·ï¼š</p>
</blockquote>
<p><font size=2>Single: <font color=red>S</font><font color=orange>EEEEEEE E</font><font color=green>FFFFFFF FFFFFFFF FFFFFFFF</font></font><br><font size=2>Double: <font color=red>S</font><font color=orange>EEEEEEE EEEE</font><font color=green>FFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF</font></font>  </p>
<h2 id="The-Sign-Bit"><a href="#The-Sign-Bit" class="headerlink" title="The Sign Bit"></a>The Sign Bit</h2><p>The sign bit is as simple as it gets: 0 denotes a positive number, and 1 denotes a negative number. Flipping the value of this bit flips the sign of the number.</p>
<blockquote>
<p>ç¬¦å·ä½æ¯”è¾ƒç®€å•ï¼Œ0ä»£è¡¨æ•´æ•°ï¼Œ1ä»£è¡¨è´Ÿæ•°ã€‚</p>
</blockquote>
<h2 id="The-Exponent"><a href="#The-Exponent" class="headerlink" title="The Exponent"></a>The Exponent</h2><p>The exponent field needs to represent both positive and negative exponents. To do this, a bias is added to the actual exponent in order to get the stored exponent. For IEEE single-precision floats, this value is 127. Thus, to express an exponent of zero, 127 is stored in the exponent field. A stored value of 200 indicates an exponent of (200âˆ’127), or 73. For reasons discussed later, exponents of âˆ’127 (all 0s) and +128 (all 1s) are reserved for special numbers.</p>
<p>Double precision has an 11-bit exponent field, with a bias of 1023.</p>
<blockquote>
<p>æŒ‡æ•°åŸŸåˆ†æ­£æ•°å’Œè´Ÿæ•°ã€‚ä¸ºäº†åŒºåˆ†ï¼Œå¼•å…¥äº†ä¸€ä¸ªåç½®æ•°ã€‚IEEEå•ç²¾åº¦æµ®ç‚¹æ•°ï¼Œè¿™ä¸ªåç½®æ•°æ˜¯127. å› æ­¤æŒ‡æ•°æ˜¯é›¶å¯¹åº”åç½®æ•°æ˜¯127ï¼Œå­˜å‚¨åœ¨æŒ‡æ•°åŸŸã€‚200å¯¹åº”çš„æŒ‡æ•°ï¼ˆ200-127ï¼‰æ˜¯73.åŸå› åœ¨åé¢è§£é‡Šã€‚æŒ‡æ•°åŸŸï¼ˆ8ä½ï¼Œå–å€¼æ˜¯0â€”â€”255ï¼‰å…¨0ä»£è¡¨-127ï¼ˆ0-127ï¼‰ï¼Œå…¨1ä»£è¡¨+128ï¼ˆ255-127ï¼‰.</p>
<p>åŒç²¾åº¦æµ®ç‚¹æ•°çš„æŒ‡æ•°åŸŸæœ‰11ä½ï¼Œå®ƒçš„åç½®æ•°æ˜¯1023.</p>
<p>æ³¨ï¼šç›²çŒœåç½®æ•°bias = 2<sup>ï¼ˆ bit_num-1 ï¼‰</sup> - 1.</p>
<p>æ³¨ï¼šä¸ºä»€ä¹ˆè¦å¼•å…¥åç½®æ•°ï¼Ÿä¸ªäººè®¤ä¸ºï¼ŒæŒ‡æ•°æ˜¯æœ‰æ­£è´Ÿä¹‹åˆ†çš„ï¼ŒæŒ‡æ•°åŸŸæ²¡å¿…è¦å†å¼•å…¥ä¸€ä¸ªç¬¦å·ä½ï¼Œé‚£ä¹ˆéœ€è¦å¼•å…¥ä¸€ä¸ªåç½®æ•°æ¥ä»£æ›¿ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œ8bitçš„æŒ‡æ•°åŸŸï¼ŒåŸæœ¬å–å€¼æ˜¯ -127 ~ +128ï¼Œå¼•å…¥åç½®æ•°ï¼ˆ127ï¼‰åå–å€¼æ˜¯0~255ï¼Œä»è€Œå»æ‰äº†æŒ‡æ•°åŸŸçš„ç¬¦å·ä½ã€‚</p>
</blockquote>
<h2 id="The-Mantissa"><a href="#The-Mantissa" class="headerlink" title="The Mantissa"></a>The Mantissa</h2><p>The mantissa, also known as the significand, represents the precision bits of the number. It is composed of an implicit leading bit (left of the radix point) and the fraction bits (to the right of the radix point).</p>
<blockquote>
<p>å°¾æ•°æ˜¯å¾ˆé‡è¦çš„ï¼Œå®ƒä½“ç°äº†æ•°å­—çš„ç²¾åº¦ã€‚å®ƒç”±éšå«çš„çš„å…ˆå¯¼ä½ï¼ˆå°æ•°ç‚¹å·¦è¾¹çš„éƒ¨åˆ†ï¼‰å’Œå°æ•°ä½ï¼ˆå°æ•°ç‚¹å³è¾¹çš„éƒ¨åˆ†ï¼‰æ„æˆã€‚</p>
</blockquote>
<p>To find out the value of the implicit leading bit, consider that any number can be expressed in scientific notation in many different ways. For example, the number 50 can be represented as any of these:</p>
<blockquote>
<p>ä¸ºäº†äº†è§£ä»€ä¹ˆæ˜¯éšå«çš„å…ˆå¯¼ä½ï¼Œè¯·çœ‹çœ‹ç”¨ç§‘å­¦æŠ€æœ¯è¡¨ç¤ºæ³•è¡¨ç¤ºä¸€ä¸ªæ•°å­—çš„å„ç§æ–¹å¼ã€‚ä¸¾ä¸ªä¾‹å­ï¼šæ•°å­—50å¯ä»¥å†™æˆè¿™æ ·ï¼š</p>
</blockquote>
<pre>
    0.050 Ã— 10<sup>3</sup>
    .5000 Ã— 10<sup>2</sup>
    5.000 Ã— 10<sup>1</sup>
    50.00 Ã— 10<sup>0</sup>
    5000. Ã— 10<sup>âˆ’2</sup>  
</pre>
<p>In order to maximize the quantity of representable numbers, floating-point numbers are typically stored in normalized form. This basically puts the radix point after the first non-zero digit. In normalized form, 50 is represented as 5.000 Ã— 10<sup>1</sup>.</p>
<blockquote>
<p>ä¸ºäº†æœ€å¤§é™åº¦åœ°è¡¨ç¤ºæ•°å­—ï¼Œæµ®ç‚¹æ•°é€šå¸¸ä»¥æ ‡å‡†åŒ–å½¢å¼å­˜å‚¨ã€‚å°†å°æ•°ç‚¹æ”¾åœ¨ç¬¬ä¸€ä¸ªï¼ˆä»å·¦å¾€å³æ•°ï¼‰éé›¶æ•°çš„å³è¾¹ã€‚æ ‡å‡†æ ¼å¼ä¸‹ï¼Œ50å°±è¦è¡¨ç¤ºæˆ5.000 Ã— 10<sup>1</sup>ã€‚</p>
</blockquote>
<p>A nice little optimization is now available to us in base two, since binary has only one possible non-zero digit: 1. Thus, we can just assume a leading digit of 1, and donâ€™t need to store it in the floating-point representation. As a result, we can assume a leading digit of 1 without storing it, so that a 32-bit floating-point value effectively has 24 bits of mantissa: 23 explicit fraction bits plus one implicit leading bit of 1.</p>
<blockquote>
<p>å¯æ˜¯åœ¨äºŒè¿›åˆ¶å½“ä¸­æˆ‘ä»¬å¯ä»¥åšä¸€ç‚¹å°å°çš„ä¼˜åŒ–ï¼ŒäºŒè¿›åˆ¶æ•°çš„ç¬¬ä¸€ä¸ªéé›¶æ•°åªæœ‰1. å› æ­¤æµ®ç‚¹è¡¨ç¤ºæ³•ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è§„å®šå…ˆå¯¼æ•°å°±æ˜¯æ•°å­—1ä¸”æ²¡å¿…è¦åœ¨ä¿å­˜å®ƒäº†ã€‚é‚£ä¹ˆ32ä½çš„æµ®ç‚¹æ•°å€¼çš„å°¾æ•°ï¼ˆè§„å®šæ˜¯23ä½ï¼‰ç­‰æ•ˆä¸º24ä½äº†ï¼š23ä½çš„æ˜¾å¼å°æ•°éƒ¨åˆ†åŠ ä¸Šä¸€ä¸ªéšå«çš„å…ˆå¯¼ä½ 1.</p>
</blockquote>
<h2 id="Putting-it-All-Together"><a href="#Putting-it-All-Together" class="headerlink" title="Putting it All Together"></a>Putting it All Together</h2><p>So, to sum up:</p>
<ol>
<li><p>The sign bit is 0 for positive, 1 for negative.</p>
</li>
<li><p>The exponent base is two.</p>
</li>
<li><p>The exponent field contains 127 plus the true exponent for single-precision, or 1023 plus the true exponent for double precision.</p>
</li>
<li><p>The first bit of the mantissa is typically assumed to be 1, yielding a full mantissa of 1.f, where f is the field of fraction bits.</p>
<blockquote>
<p>æ€»ç»“ä¸‹ï¼š</p>
<ol>
<li>ç¬¦å·ä½0ä»£è¡¨æ•´æ•°ï¼Œ1ä»£è¡¨è´Ÿæ•°ã€‚</li>
<li>æŒ‡æ•°æ˜¯äºŒè¿›åˆ¶ã€‚</li>
<li>æŒ‡æ•°åŸŸçš„å€¼æ˜¯å®é™…æŒ‡æ•°åŠ ä¸Š127ï¼ˆå•ç²¾åº¦ï¼‰æˆ–è€…åŠ ä¸Š1023ï¼ˆåŒç²¾åº¦ï¼‰ã€‚</li>
<li>å°¾æ•°çš„ç¬¬ä¸€ä½è§„å®šæ˜¯1ï¼Œå°¾æ•°å°±æ˜¯1.fï¼ŒfæŒ‡å°æ•°éƒ¨åˆ†ã€‚</li>
</ol>
</blockquote>
<h2 id="Ranges-of-Floating-Point-Numbers"><a href="#Ranges-of-Floating-Point-Numbers" class="headerlink" title="Ranges of Floating-Point Numbers"></a>Ranges of Floating-Point Numbers</h2><p>Letâ€™s consider single-precision floats for a second. Weâ€™re taking essentially a 32-bit number and reinterpreting the fields to cover a much broader range. Something has to give, and that something is precision. For example, regular 32-bit integers, with all precision centered around zero, can precisely store integers with 32-bits of resolution. Single-precision floating-point, on the other hand, is unable to match this resolution with its 24 bits. It does, however, approximate this value by effectively truncating from the lower end and rounding up. For example:</p>
</li>
</ol>
<blockquote>
<p>æµ®ç‚¹æ•°çš„è¡¨ç¤ºèŒƒå›´</p>
<p>æˆ‘ä»¬å…ˆæ¥è€ƒè™‘ä¸‹å•ç²¾åº¦ã€‚æˆ‘ä»¬åŸºæœ¬ä¸Šé‡‡ç”¨ 32 ä½æ•°å­—å¹¶é‡æ–°è§£é‡Šè¿™äº›å­—æ®µï¼Œä»è€Œå¯æ‹“å±•åˆ°æ›´å¤§çš„èŒƒå›´ã€‚é¦–å…ˆå¾—æŒ‡å‡ºç²¾åº¦èŒƒå›´ã€‚ä¾‹å¦‚ï¼Œæ‰€æœ‰ä»¥é›¶ä¸ºä¸­å¿ƒçš„32ä½æ•´æ•°ï¼Œå¯ä»¥ç”¨32ä½çš„åˆ†è¾¨åŠ›ç²¾å‡†åœ°å­˜å‚¨æ•´æ•°ã€‚å¦å¤–ï¼Œå•ç²¾åº¦çš„æµ®ç‚¹ï¼Œå®ƒçš„24ä½å¯ä¸è¶³ä»¥åŒ¹é…32ä½çš„åˆ†è¾¨åŠ›ã€‚ä½†æ˜¯å®ƒç¡®å®å¯ä»¥ï¼Œé€šè¿‡æœ‰æ•ˆåœ°ä»ä½ç«¯æˆªæ–­å¹¶å‘ä¸Šå–æ•´æ¥è¿‘ä¼¼è¯¥å€¼ã€‚</p>
</blockquote>
<pre>
    11110000 11001100 10101010 10101111  // 32-bit integer
= +1.1110000 11001100 10101011 x 2<sup>31</sup>     // Single-precision float
=   11110000 11001100 10101011 00000000  // Actual float value
</pre>
<p>This approximates the 32-bit value, but doesnâ€™t yield an exact representation. On the other hand, besides the ability to represent fractional components (which integers lack completely), the floating-point value can represent numbers around 2<sup>127</sup>, compared to 32-bit integersâ€™ maximum value around 2<sup>32</sup>.</p>
<blockquote>
<p>è¿™åªæ˜¯è¿‘ä¼¼çš„32ä½æ•°å€¼ï¼Œä¸æ˜¯å‡†ç¡®çš„ã€‚å¦ä¸€æ–¹é¢ï¼Œé™¤äº†èƒ½è¡¨ç¤ºå°æ•°éƒ¨åˆ†ï¼ˆå®Œå…¨æ²¡æœ‰æ•´æ•°éƒ¨åˆ†ï¼‰ï¼Œæµ®ç‚¹å€¼ä¹Ÿå¯ä»¥è¡¨ç¤º2<sup>127</sup>ï¼Œè€Œå¯¹æ¯”32æ¯”ç‰¹çš„æœ€å¤§å€¼æ˜¯2<sup>32</sup>.</p>
</blockquote>
<p>The range of positive floating point numbers can be split into normalized numbers (which preserve the full precision of the mantissa), and denormalized numbers (which assume a leading digit of 0, discussed later) which use only a portion of the fractionsâ€™s precision.</p>
<blockquote>
<p>æ­£æµ®ç‚¹æ•°çš„èŒƒå›´å¯ä»¥åˆ†ä¸ºæ ¼å¼åŒ–æ•°ï¼ˆä¿å­˜å°¾æ•°çš„å…¨ç²¾åº¦ï¼‰å’Œéæ ¼å¼åŒ–æ•°ï¼ˆæ­¤æ—¶å…ˆå¯¼æ•°æ˜¯é›¶ï¼‰ã€‚</p>
</blockquote>
<p>â€‹                                                      <em>Floating Point Range</em></p>
<table>
<thead>
<tr>
<th></th>
<th>Denormalized</th>
<th>Normalized</th>
<th>Approximate Decimal</th>
</tr>
</thead>
<tbody><tr>
<td>Single Precision</td>
<td>Â± 2<sup>-149</sup> to (1âˆ’2<sup>âˆ’23</sup>)Ã—2<sup>-126</sup></td>
<td>Â± 2<sup>-126</sup> to (2âˆ’2<sup>âˆ’23</sup>)Ã—2<sup>127</sup></td>
<td>Â± â‰ˆ10<sup>âˆ’44.85</sup> to â‰ˆ10<sup>38.53</sup></td>
</tr>
<tr>
<td>Double Precision</td>
<td>Â± 2<sup>âˆ’1074</sup> to (1âˆ’2<sup>âˆ’52</sup>) Ã— 2<sup>âˆ’1022</sup></td>
<td>Â± 2<sup>âˆ’1022</sup> to (2âˆ’2<sup>âˆ’52</sup>)Ã—2<sup>1023</sup></td>
<td>Â± â‰ˆ10<sup>âˆ’323.3</sup> to â‰ˆ10<sup>308.3</sup></td>
</tr>
</tbody></table>
<blockquote>
<p>åé¢æœ‰ç©ºå†ç¿»è¯‘ã€‚</p>
</blockquote>
<p>Since every floating-point number has a corresponding, negated value (by toggling the sign bit), the ranges above are symmetric around zero.</p>
<p>There are five distinct numerical ranges that single-precision floating-point numbers are not able to represent with the scheme presented so far:</p>
<ol>
<li>Negative numbers less than âˆ’(2âˆ’2<sup>âˆ’23</sup>) Ã— 2<sup>127</sup> (negative overflow)</li>
<li>Negative numbers greater than âˆ’2<sup>âˆ’149</sup> (negative underflow)</li>
<li>Zero</li>
<li>Positive numbers less than 2<sup>âˆ’149</sup> (positive underflow)</li>
<li>Positive numbers greater than (2âˆ’2<sup>âˆ’23</sup>) Ã— 2<sup>127</sup> (positive overflow)</li>
</ol>
<p>Overflow means that values have grown too large for the representation, much in the same way that you can overflow integers. Underflow is a less serious problem because is just denotes a loss of precision, which is guaranteed to be closely approximated by zero.</p>
<p>Hereâ€™s a table of the total effective range of finite IEEE floating-point numbers:</p>
<p>â€‹                                            <em>Effective Floating-Point Range</em></p>
<table>
<thead>
<tr>
<th></th>
<th>Binary</th>
<th>Decimal</th>
</tr>
</thead>
<tbody><tr>
<td>Single</td>
<td>Â± (2âˆ’2<sup>âˆ’23</sup>) Ã— 2<sup>127</sup></td>
<td>â‰ˆ Â± 10<sup>38.53</sup></td>
</tr>
<tr>
<td>Double</td>
<td>Â± (2âˆ’2<sup>âˆ’52</sup>) Ã— 2<sup>1023</sup></td>
<td>â‰ˆ Â± 10<sup>308.25</sup></td>
</tr>
</tbody></table>
<p><em>Note that the extreme values occur (regardless of sign) when the exponent is at the maximum value for finite numbers (2<sup>127</sup> for single-precision, 2<sup>1023</sup> for double), and the mantissa is filled with 1s (including the normalizing 1 bit).</em></p>
<h2 id="Special-Values"><a href="#Special-Values" class="headerlink" title="Special Values"></a>Special Values</h2><p>IEEE reserves exponent field values of all 0s and all 1s to denote special values in the floating-point scheme.</p>
<h3 id="Denormalized"><a href="#Denormalized" class="headerlink" title="Denormalized"></a><em>Denormalized</em></h3><p>If the exponent is all 0s, then the value is a denormalized number, which now has an assumed leading 0 before the binary point. Thus, this represents a number (âˆ’1)s Ã— 0.f Ã— 2<sup>âˆ’126</sup>, where s is the sign bit and f is the fraction. For double precision, denormalized numbers are of the form (âˆ’1)s Ã— 0.f Ã— 2<sup>âˆ’1022</sup>.</p>
<p>As denormalized numbers get smaller, they gradually lose precision as the left bits of the fraction become zeros. At the smallest non-zero denormalized value (only the least-significant fraction bit is one), a 32-bit floating-point number has but a single bit of precision, compared to the standard 24-bits for normalized values.</p>
<h3 id="Zero"><a href="#Zero" class="headerlink" title="Zero"></a><em>Zero</em></h3><p>You can think of zero as a denormalized number (an implicit leading 0 bit) with all 0 fraction bits. Note that âˆ’0 and +0 are distinct values, though they both compare as equal.</p>
<h3 id="Infinity"><a href="#Infinity" class="headerlink" title="Infinity"></a><em>Infinity</em></h3><p>The values +âˆ and âˆ’âˆ are denoted with an exponent of all 1s and a fraction of all 0s. The sign bit distinguishes between negative infinity and positive infinity. Being able to denote infinity as a specific value is useful because it allows operations to continue past overflow situations. Operations with infinite values are well defined in IEEE floating point.  </p>
<h3 id="Not-A-Number"><a href="#Not-A-Number" class="headerlink" title="Not A Number"></a><em>Not A Number</em></h3><p>The value NaN (Not a Number) is used to represent a value that does not represent a real number. NaNâ€™s are represented by a bit pattern with an exponent of all 1s and a non-zero fraction. There are two categories of NaN: QNaN (Quiet NaN) and SNaN (Signalling NaN).</p>
<p>A QNaN is a NaN with the most significant fraction bit set. QNaNâ€™s propagate freely through most arithmetic operations. These values are generated from an operation when the result is not mathematically defined.</p>
<p>An SNaN is a NaN with the most significant fraction bit clear. It can be used to signal an exception when used in operations. SNaNâ€™s can be handy to assign to uninitialized variables to trap premature usage.</p>
<p>Semantically, QNaNâ€™s denote indeterminate operations, while SNaNâ€™s denote invalid operations.</p>
<h2 id="Special-Operations"><a href="#Special-Operations" class="headerlink" title="Special Operations"></a>Special Operations</h2><p>Operations on special numbers are well-defined by IEEE. In the simplest case, any operation with a NaN yields a NaN result. Other operations are as follows:</p>
<p>â€‹                                                <em>Special Arithmetic Results</em></p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Result</th>
</tr>
</thead>
<tbody><tr>
<td>n Ã· Â±âˆ</td>
<td>0</td>
</tr>
<tr>
<td>Â±âˆ Ã— Â±âˆ</td>
<td>Â±âˆ</td>
</tr>
<tr>
<td>Â±nonZero Ã· Â±0</td>
<td>Â±âˆ</td>
</tr>
<tr>
<td>Â±finite Ã— Â±âˆ</td>
<td>Â±âˆ</td>
</tr>
<tr>
<td>âˆ + âˆ âˆ âˆ’ âˆ’âˆ</td>
<td>+âˆ</td>
</tr>
<tr>
<td>âˆ’âˆ âˆ’ âˆ âˆ’âˆ + âˆ’âˆ</td>
<td>âˆ’âˆ</td>
</tr>
<tr>
<td>âˆ âˆ’ âˆ âˆ’âˆ + âˆ</td>
<td>NaN</td>
</tr>
<tr>
<td>Â±0 Ã· Â±0</td>
<td>NaN</td>
</tr>
<tr>
<td>Â±âˆ Ã· Â±âˆ</td>
<td>NaN</td>
</tr>
<tr>
<td>Â±âˆ Ã— 0</td>
<td>NaN</td>
</tr>
<tr>
<td>NaN == NaN</td>
<td>false</td>
</tr>
</tbody></table>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>To sum up, the following are the corresponding values for a given representation:</p>
<p><em>Float Values (b = bias)</em><br><img src="FloatValues.png" alt="FlooatValues"></p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>A lot of this stuff was observed from small programs I wrote to go back and forth between hex and floating point (printf-style), and to examine the results of various operations. The bulk of this material, however, was lifted from Stallingsâ€™ book.</p>
<ol>
<li><em>Computer Organization and Architecture, William Stallings, pp. 222â€“234 Macmillan Publishing Company, ISBN 0-02-415480-6</em></li>
<li><em>IEEE Computer Society (1985), IEEE Standard for Binary Floating-Point Arithmetic, IEEE Std 754-1985.</em></li>
<li><em>Intel Architecture Software Developerâ€™s Manual, Volume 1: Basic Architecture, (a PDF document downloaded from <a target="_blank" rel="noopener" href="https://www.intel.com/content/www/us/en/homepage.html">intel.com</a>).</em></li>
</ol>
<h2 id="See-Also"><a href="#See-Also" class="headerlink" title="See Also"></a>See Also</h2><ul>
<li><p><em><a target="_blank" rel="noopener" href="https://standards.ieee.org/">IEEE Standards Site</a></em></p>
</li>
<li><p><em><a target="_blank" rel="noopener" href="https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/">Comparing floating point numbers</a>, Bruce Dawson. This is an excellent article on the traps, pitfalls and solutions for comparing floating point numbers. Hint â€“ epsilon comparison is usually the wrong solution.</em></p>
</li>
<li><p><em><a target="_blank" rel="noopener" href="https://randomascii.wordpress.com/2012/05/20/thats-not-normalthe-performance-of-odd-floats/">Thatâ€™s Not Normal â€“ the Performance of Odd Floats</a>, Bruce Dawson. This is another good article covering performance issues with IEEE specials on x86 architecture.</em></p>
</li>
<li><p><em><a target="_blank" rel="noopener" href="http://c.biancheng.net/view/314.html">IEEE 754æµ®ç‚¹æ•°æ ‡å‡†è¯¦è§£</a></em></p>
</li>
</ul>

  <p> â€” 2021å¹´7æœˆ29æ—¥</p>
  


          <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with â¤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
        at <a href="https://en.wikipedia.org/wiki/Earth" target="_blank" rel="noreferrer">Earth</a>.</p>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/MaNan93" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      

      

      

      

    </div>
  
</div>

        </div>
      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>
  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>
